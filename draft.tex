\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{biblatex} % Imports biblatex package
\addbibresource{references.bib}
\usepackage{changepage}
\usepackage{parskip}

\title{Creating More Meaningful Explanations for Audio Deepfake Detection}
\date{2024-10-01} 
\author{Jacob LaRock\\1667321}
\linespread{1.5}

\def\Institute{Universität Siegen}
\def\KindOfWork{Bachelorarbeit}
\def\Studiengang{Wirtschaftsinformatik}
\def\Fakultaet{Fakultät III: Wirtschaftswissenschaften, Wirtschaftsinformatik und Wirtschaftsrecht}
 
\def\Title{Creating More Meaningful Explanations for Audio Deepfake Detection}
\def\Subtitle{}
 
\def\student{Jaocb LaRock}
\def\studentno{1667321}
\def\place{Siegen}
\def\Date{31.03.2025} 
\def\semester{6}
 
\def\erstpruefer{Gunnar Stevens}
\def\erstprueferMail{Gunnar.Stevens@uni-siegen.de}

\begin{document}
	\begin{titlepage}
        \begin{minipage}{0.9\linewidth}
			\centering
			\includegraphics [width=0.35\textwidth]{images/LogoSiegen}
        \end{minipage}

		\vspace{2cm}

		\centering

		{\Large\bfseries \Title\par}
		{\large\bfseries \Subtitle\par}
		\vspace{2cm}

		{\large \textbf{\KindOfWork}\par}

		\vspace{1.5cm}

		{\normalsize im Studiengang \\
			\Studiengang  im \semester. Semester \\
		}
		\vspace{0.5cm}
		{\normalsize vorgelegt von}
		\vspace{0.5cm}

		{\normalsize \textbf{\student} \\
			Matr.-Nr.: \studentno  \\}
		{am \normalsize \Date\par}

		\vspace{0.5cm}

		{\Institute} \par
		{\Fakultaet}\par

		\vspace{1cm}

    {\begin{table}[h]
			\centering
			\begin{tabular}{lll}
				{Erstprüfer:} & \erstpruefer & \erstprueferMail \\
			\end{tabular}
		\end{table}}     
		\vfill
	\end{titlepage}
    \newpage
    \section{Abstract}
    Abstract filler text blablabla!
    \section{Introduction}
    As the use of generative methods for the creation of synthetic voices becomes more widespread,
    so grows the need for reliable and usable detection methods for the protection of the security
    of people and businesses alike. In particular, the rise of deepfake technology has led to
	concerns about its potential misuse in areas such as politics, entertainment, and national
	security by, for instance, potentially allowing malicious actors to create fake audio
	recordings that appear to be genuine statements made by public figures or to create
	genuine-seeming recordings of events that never happened, which could have significant
	consequences if used to spread misinformation, from defaming individuals to creating political
	tension \cite{veerasamy_rising_2022,albahar_deepfakes_2005}. The field of Explainable AI (XAI)
	shows promise for producing useful and interpretable results from such models. Explainable AI
	refers to the ability of artificial intelligence systems, such as machine learning models and
	neural networks, to provide understandable and interpretable explanations for their decisions
	or predictions. This means that XAI systems can articulate why they made a particular
	decision, what factors influenced it, and how confident they are in their conclusion
	\cite{hind_explaining_2019}. For the detection of audio deepfakes, this could mean that the
	model can justify its classification with feature-based evidence, allowing for verification of
	the result by the end user. Much of the existing research, further discussed in the next
	section, follows the path of producing a model with the best possible benchmarks against
	datasets of samples, without taking into account if the results can be usefully interpreted,
	while existing explorations into making audio deepfake detection explainable have produced
	results that often require a lot of background knowledge to meaningfully interpret With the
	context of the research discussed in the next section, I would like to use new combinations of
	features with a novel model architecture to generate explanations for fake or real audio
	classification that are potentially more useful to their end user.
	\section{Related Work}
	\section{Experiments}
		\subsection{Dataset}
		\subsection{Black-Box Model}
		The model used for this experiment was made, trained and evaluated using the tools
		available in the TensorFlow and Keras libraries \cite{tensorflow2015-whitepaper}. This
		section will go into further detail about the experimental setup for the black-box model
		as well as the way in which explanations were created and summarized.
			\subsubsection{Features}
			Several features were used for the final version of the black-box model. Some are
			features that can be called generic, widely used in research involving the detection
			of synthetic while others are more specific and are cited accordingly. The features
			that are not summarized for a whole sample are extracted using a sliding window method,
			preventing a loss of fidelity that can be caused by compression of the feature to a
			standard size. The features used are as follows:
			\begin{itemize}
				\item
					\sloppy
					Harmonic-to-noise ratios: Inspired by previous research
					\cite{chaiwongyen_contribution_2022,chaiwongyen_deepfake-speech_2023,
					li_comparative_2022} but slightly modified from the original concept, the HNRs
					are the ratios of the strengths of harmonic frequencies to the strengths of
					"noise", the total strength outside the harmonic frequencies. Unlike some
					previously seen examples \cite{chaiwongyen_contribution_2022,
					chaiwongyen_deepfake-speech_2023}, I calculate this ratio for each fundamental
					frequency length, instead of using one value for the whole sample. Given that
					 \(\gamma_{i}\) is the harmonic energy in a given fundamental frequency cycle
					 and \(\iota_{i}\) is the residual energy in a given fundamental frequency
					 cycle, the HNR at that cycle is calculated as follows:
					 \[ 20log\frac{\gamma_{i}}{\iota_{i}} \]
				\item
					Mel-spectrograms: A widely-used feature in synthetic audio detection, the
					mel-spectrogram is a spectrographic representation of an audio sample
					transformed in a manner to better represent human perception of frequencies
					\cite{qais_deepfake_2022}.
				\item
					Mel-frequency cepstral coefficients: The derivative cepstral coefficients of
					the mel-spectrogram, also widely-seen in research on synthetic audio detection.
				\item
					Fundamental frequency lengths: The lengths of every fundamental frequency
					cycle in the sample. This has also been previously used in certain research on
					synthetic audio detection \cite{xue_audio_2022}. The output is one-dimensional
					with time as the axis.
				\item
					Onset strength: As used in previous research \cite{li_comparative_2022}, the
					strengths of each onset in the audio sample, where an onset is point where
					there is a sudden rise in energy across the audio spectrum. This results in a
					one-dimensional output with time as the axis.
				\item
					Intensity: Also inspired by previoous research \cite{li_comparative_2022},
					intensity is the total power at each point in the audio sample, given in db.
					This is calculated by creating a fourrier transformation of the sample and then
					summing across the frequency-axis for every point on the time-axis. Resulting
					in a one-dimensional output.
				\item
					Pitch-fluctuations: Calculated for every sample in the audio as the difference
					between pitch at the given point and the pitch at the previous point. Pitch is
					estimated based on the maximum power harmonics. This feature is not identical
					to, but is inspired by the use of summarized pitch fluctuations in previous
					research \cite{khanjani_learning_2023}. This feature is also one-dimensional
					with time as the axis. Given that \(H_{i}\) is the set of harmonic frequencies
					at fundamental frequency cycle \(i\) and \(s(h_{i})\) is the power of a given
					harmonic frequency at cycle \(i\), the pitch can be estimated as follows:
					\[p_{i} = s(max(H_{i}))\]
					Then, given an offset \(x\), the pitch fluctuations can be calculated as
					follows:
					\[p_{i}-p_{i-x}\]
				\item
					Jitter features: As defined in previous attempts to identify synthetic audio
					\cite{chaiwongyen_deepfake-speech_2023} with perceptible features,
					jitter-based features measures the absolute variations in fundamental
					frequency cycles in comparison to the nearest x neighbors using the following
					method:
					\[ \frac{ \frac{1}{N-1}\sum_{i=1}^{N-1}|T_{i}(\frac{1}{x}\sum_{n=i-m}^{i+m}T_{n})|}
					{\frac{1}{N}\sum_{i=1}^{N}T_{i}} \]
					where \(T_{i}\) represents the extracted fundamental frequency lengths and
					\(N\) is the number of fundamental frequency periods.
				\item
					Shimmer features: Similarly defined to the jitter features, shimmer features
					instead use the amplitudes at each fundamental frequency period. Their purpose
					is to capture irregular vocal fold vibrations which may be an indication but
					not a guarantee of a synthetic voice \cite{chaiwongyen_deepfake-speech_2023}.
					\[ \frac{ \frac{1}{N-1}\sum_{i=1}^{N-1}|A_{i}(\frac{1}{x}\sum_{n=i-m}^{i+m}A_{n})|}
					{\frac{1}{N}\sum_{i=1}^{N}A_{i}} \]
			\end{itemize}
			\subsubsection{Model Architecture}
			The general architecture is designed to allow the combination of diverse features into
			one final prediction, regardless of whether the individual features have the same
			shape. This is achieved by using a separate model for each feature, with its own input
			and output layers (further referred to as sub-models), which are then concatenated
			together and pooled into a final output value (in what I will further refer to as the
			terminus). This modular structure allows not only better performance and less memory
			use, due to the fact that fewer transformations are required in input preparation, but
			also allows for more flexibility in the construction of the model, making it easy to
			add and remove features using pre-defined functions depending on feature type. This
			kind of architecture also provides an advantage to the generation of explanations, as
			only the terminus part of the entire must be explained to interpret the importance of
			each input feature. Further explanation is in the following section.
		\subsection{Explanations}
	\section{Results}
		\subsection{Black-Box Model Results}
		\subsection{Explanation Results}
	\section{Discussion}
	\section{Conclusion}
	\newpage
	\printbibliography
\end{document}
